{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Custom Transformers, Pipelines, and Ensemble Models to Predict Venue Ratings from the Yelp Academic Dataset\n",
    "\n",
    "<span id='back-up'>The Yelp academic dataset </span> (included in this repository) consists of about 38,000 business listings and their relevant information. Each listing includes 15 properties, e.g. `business_id`, `full_address`, `hours`, `categories`, etc ([Click here to see all of a listing's properties](#listing)).\n",
    "\n",
    "The **goal of this project** is to demonstrate the use of custom transformer classes, chaining custom tranformers/estimators into pipelines for composite estimators, and using feature unions to develop an ensemble model for venues' ratings prediction.\n",
    "\n",
    "Although I will optimize my models using cross-validation, the goal of the project is *not to develop the best* model to predict star ratings based on the features in the dataset. This dataset doesn't include actual user reviews. A much more accurate predictive model would likely require natural language processing (NLP) of the costumer review data. With that caveat, let's dive into the data.\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Used\n",
    "\n",
    "I will be using the most common python libaries for machine learning and data analysis, namely the numpy, pandas and scikit-learn libraries. I'll be using sci-kit learn's linear and non-linear regressors for modeling the data. As most of the data is not in the correct format (sci-kit learn requires numpy arrays or pandas dataframes as inputs) I'll write custom transformers to modify the original data structure for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn import base\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import gzip\n",
    "\n",
    "with gzip.open('yelp_train_academic_dataset_business.json.gz') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id='listing'> I always find it nice to see how the data is structured. `data` is a a list of businesses (~38,000). I have just printed the first listed buisness to see all of it's associated metadata ([back to the introduction](#back-up)). </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id : vcNAWiLM4dR7D2nwwJ7nCA\n",
      "full_address : 4840 E Indian School Rd\n",
      "Ste 101\n",
      "Phoenix, AZ 85018\n",
      "hours : {'Tuesday': {'close': '17:00', 'open': '08:00'}, 'Friday': {'close': '17:00', 'open': '08:00'}, 'Monday': {'close': '17:00', 'open': '08:00'}, 'Wednesday': {'close': '17:00', 'open': '08:00'}, 'Thursday': {'close': '17:00', 'open': '08:00'}}\n",
      "open : True\n",
      "categories : ['Doctors', 'Health & Medical']\n",
      "city : Phoenix\n",
      "review_count : 7\n",
      "name : Eric Goldberg, MD\n",
      "neighborhoods : []\n",
      "longitude : -111.983758\n",
      "state : AZ\n",
      "stars : 3.5\n",
      "latitude : 33.499313\n",
      "attributes : {'By Appointment Only': True}\n",
      "type : business\n"
     ]
    }
   ],
   "source": [
    "for i in data[0]:\n",
    "    print (i,':', data[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the labels separate from the features and splitting the dataset into a training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ratings = [business['stars'] for business in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6729137013021247"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(star_ratings).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data, star_ratings, \n",
    "                                                train_size=0.8, \n",
    "                                                random_state=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a City-based Predictive Model\n",
    "\n",
    "This first estimator takes all the cities in the dataset, calculates the average, and then predicts that average for any venue in a city.\n",
    "\n",
    "As a a model, it is quite crude, but in some cases where customers in some cities may rate higher than other cities, it would make for a baseline predictor, especially when combined with category data.\n",
    "\n",
    "I added a default rating of 3.67 (dataset mean) if the city doesn't exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # X is input list of rows. y is corresponding star ratings\n",
    "        city = [business['city'] for business in X]\n",
    "        \n",
    "        # using dataframes for grouped means\n",
    "        city_stars = pd.DataFrame({'city': city,\n",
    "                                   'star_ratings': y})\n",
    "        city_avg = city_stars.groupby(['city'], as_index=False).mean()\n",
    "        \n",
    "        # going back to the dictionary as easier to add missing data during predict\n",
    "        agg_city = city_avg['city'].to_list()\n",
    "        agg_stars = city_avg['star_ratings'].to_list()\n",
    "\n",
    "        self.city_agg = {i:j for i,j in zip(agg_city, agg_stars)}\n",
    "   \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        predX = [business['city'] for business in X]\n",
    "        predY = []\n",
    "        for i in predX:\n",
    "            if i in self.city_agg:\n",
    "                predY.append(self.city_agg[i])\n",
    "            else:\n",
    "                predY.append(3.67) # if city is not in dataset, if just guesses 2.5\n",
    "        return predY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using the mean squared error and the mean absolute error as my scoring metric. The former is the sum of the squared difference, whereas the latter is the sum of the absolute difference between actual `y` and predicted `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_score(model, xdata, ydata):\n",
    "    pred = model.predict(xdata)\n",
    "    score = []\n",
    "    score.append(mean_squared_error(ydata, pred))\n",
    "    score.append(mean_absolute_error(ydata,pred))\n",
    "    return pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityEstimator()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing Model\n",
    "city_est = CityEstimator()\n",
    "city_est.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8121962490416534, 0.7198220103416592]\n"
     ]
    }
   ],
   "source": [
    "# Testing with original data\n",
    "city_test_pred, city_score = pred_score(city_est, xtest, ytest)\n",
    "print(city_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance the MSE of 0.81 and MAE of 0.72 looks low. But if we plot our data, we'll see that our data is centered at 3.67. a MAE of 0.72 suggests the average prediction could range from 2.95 to  4.39, a fairly bigger when it comes to user ratings.\n",
    "\n",
    "Let's plot some subset of the data to visualize our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe80a0a290>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "city_venue = list(range(0,len(xtest)))\n",
    "plt.figure(figsize=(12,6))\n",
    "w = 100 # shift window to plot\n",
    "plt.plot(city_venue[w+0:w+100], ytest[w+0:w+100], 'r.' ,label='Actual')\n",
    "plt.plot(city_venue[w+0:w+100], city_test_pred[w+0:w+100], 'bo' ,label='Pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model does a really poor job of predicting most venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 102.,  146.,  284.,  620., 1050., 1697., 1667., 2022.]),\n",
       " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 8 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ytest, bins=8, range=(1,5), edgecolor='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Select Transformer \n",
    "\n",
    "If I want to use particular features as input for a model, I have to make sure it is shaped as a numpy array for sci-kit learn's regressors. The format of a numpy array is `[[$a_{1}$,$b_{1}$], [$a_{2}$,$b_{2}$], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tx_undata = [] #not formatted so UNformatted DATA\n",
    "        for i in self.col_names:\n",
    "            tx_undata.append([row[i] for row in X])\n",
    "\n",
    "        len_col = len(tx_undata)\n",
    "\n",
    "        tx_data = []\n",
    "        for i in tx_undata[0]:\n",
    "            tx_data.append([i])\n",
    "        for i in range(1, len(self.col_names)):\n",
    "            for j in range(len(tx_data)):\n",
    "                tx_data[j].append(tx_undata[i][j])\n",
    "\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names\n",
    "        return tx_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing that our column transformer takes in a list of columns, and then outputs that in a numpy array-like list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.499313, -111.983758], [43.238893, -89.335844], [43.252267, -89.353437], [43.251045, -89.374983], [43.2408748, -89.3437217]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "col_in = ['latitude', 'longitude']\n",
    "cst = ColumnSelectTransformer(col_in)\n",
    "data_subset = data[0:5]\n",
    "cst2 = cst.fit_transform(data_subset)\n",
    "cst3 = [[i['latitude'], i['longitude']] for i in data_subset]\n",
    "print(cst2)\n",
    "print(cst2 == cst3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use `pipeline` from the sklearn.pipeline library to sequentially apply my column transformer, and then pass that data to a regressor. In this case I will be using a k-nearest neighbors regressor, which averages the value of the k nearest neighbors (Euclidean distance) to predict the value for input (lat, long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_in = ['latitude', 'longitude']\n",
    "\n",
    "pipe = Pipeline([('columntx', ColumnSelectTransformer(col_in)),\n",
    "                 ('knear', KNeighborsRegressor(n_jobs=-1))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the exhaustive `GridSearchCV` function from the scikit library to optimize the `n_neighbors` and `weights` of each neighbor in the knn algorithm. Note that to pipe the parameter grid, I have to append the estimator name (that I can name arbitrarily) as `name__`. In this particular case, it is `knear__`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntx',\n",
       "                                        ColumnSelectTransformer(col_names=['latitude',\n",
       "                                                                           'longitude'])),\n",
       "                                       ('knear',\n",
       "                                        KNeighborsRegressor(algorithm='auto',\n",
       "                                                            leaf_size=30,\n",
       "                                                            metric='minkowski',\n",
       "                                                            metric_params=None,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            n_neighbors=5, p=2,\n",
       "                                                            weights='uniform'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'knear__n_neighbors': [90, 100, 110, 120, 200],\n",
       "                         'knear__weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kparams = { 'knear__n_neighbors': [90, 100, 110, 120, 200],\n",
    "            'knear__weights': ['uniform', 'distance']}\n",
    "\n",
    "cn = GridSearchCV(pipe, kparams, cv=5, scoring='neg_mean_squared_error')\n",
    "cn.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knear__n_neighbors': 100, 'knear__weights': 'uniform'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntx',\n",
       "                 ColumnSelectTransformer(col_names=['latitude', 'longitude'])),\n",
       "                ('knear',\n",
       "                 KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                     metric='minkowski', metric_params=None,\n",
       "                                     n_jobs=-1, n_neighbors=100, p=2,\n",
       "                                     weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('columntx', ColumnSelectTransformer(col_in)),\n",
    "                 ('knear', KNeighborsRegressor(n_neighbors=100, n_jobs=-1))])\n",
    "pipe.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7994039536109647, 0.7094517659462309]\n"
     ]
    }
   ],
   "source": [
    "print(pred_score(pipe,xtest, ytest)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latitude and longitude model barely improves our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tree Services', 'Home Services', 'Contractors']\n",
      "['Active Life', 'Golf']\n",
      "['Fast Food', 'Japanese', 'Restaurants']\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "\n",
    "print(data[rd.randrange(0,len(data))]['categories'])\n",
    "print(data[rd.randrange(0,len(data))]['categories'])\n",
    "print(data[rd.randrange(0,len(data))]['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictEncoder(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ct_dt = []\n",
    "        # the extra loop is because this is a list nested in a list nested in a list\n",
    "        for i in X:\n",
    "            for j in i:\n",
    "                ct_dt.append({})\n",
    "                for k in j:\n",
    "                    ct_dt[-1][k] = 1\n",
    "\n",
    "        return ct_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Doctors', 'Health & Medical']]\n",
      "[['Restaurants']]\n",
      "[['American (Traditional)', 'Restaurants']]\n",
      "[['Food', 'Ice Cream & Frozen Yogurt', 'Fast Food', 'Restaurants']]\n",
      "[['Chinese', 'Restaurants']]\n",
      "\n",
      "\n",
      "{'Doctors': 1, 'Health & Medical': 1}\n",
      "{'Restaurants': 1}\n",
      "{'American (Traditional)': 1, 'Restaurants': 1}\n",
      "{'Food': 1, 'Ice Cream & Frozen Yogurt': 1, 'Fast Food': 1, 'Restaurants': 1}\n",
      "{'Chinese': 1, 'Restaurants': 1}\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 7)\t1.0\n"
     ]
    }
   ],
   "source": [
    "col_in = ['categories']\n",
    "cst = ColumnSelectTransformer(col_in).fit_transform(data_subset)\n",
    "for i in cst:\n",
    "    print(i)\n",
    "print('\\n')\n",
    "\n",
    "cst2 = DictEncoder().fit_transform(cst)\n",
    "for i in cst2:\n",
    "    print(i)\n",
    "\n",
    "cst3 = DictVectorizer().fit_transform(cst2)\n",
    "for i in cst3:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_in = ['categories']\n",
    "pipe2 = Pipeline([('columntx', ColumnSelectTransformer(col_in)),\n",
    "                  ('dict_enc', DictEncoder()),\n",
    "                  ('dict_vec', DictVectorizer()),\n",
    "                  ('ridge', Ridge())])\n",
    "\n",
    "kparams = { 'ridge__alpha': [3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 10.0]}\n",
    "\n",
    "catn = GridSearchCV(pipe2, kparams, cv=5, scoring='neg_mean_squared_error')\n",
    "catn.fit(xtrain, ytrain)\n",
    "catn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_in = ['categories']\n",
    "pipe2 = Pipeline([('column tx', ColumnSelectTransformer(col_in)),\n",
    "                  ('dict fixer', DictEncoder()),\n",
    "                  ('dict vector', DictVectorizer()),\n",
    "                  ('ridge model', Ridge(alpha=7.0))])\n",
    "\n",
    "pipe2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_score(pipe2, xtest, ytest)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictAttEncoder(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        #self.at_lt = X   # attribute list\n",
    "        at_dt = []  # attribute flat dictionary\n",
    "        for i in X:\n",
    "            for j in i:\n",
    "                at_dt.append({})\n",
    "                for k, l in j.items():\n",
    "                    if not type(l) is dict:\n",
    "                        if l == False:\n",
    "                            at_dt[-1][k] = 0\n",
    "                        elif l == True:\n",
    "                            at_dt[-1][k] = 1\n",
    "                        else:\n",
    "                            at_dt[-1]['{}_{}'.format(k, l)] = 1\n",
    "                    if type(l) is dict:\n",
    "                        for m, n in l.items():\n",
    "                            if n == False:\n",
    "                                at_dt[-1]['{}_{}'.format(k, m)] = 0\n",
    "                            elif n == True:\n",
    "                                at_dt[-1]['{}_{}'.format(k, m)] = 1\n",
    "\n",
    "        return at_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_in = ['attributes']\n",
    "cst = ColumnSelectTransformer(col_in).fit_transform(data_subset)\n",
    "for i in cst:\n",
    "    print(i)\n",
    "print('\\n')\n",
    "\n",
    "cst2 = DictAttEncoder().fit_transform(cst)\n",
    "for i in cst2:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_in = ['attributes']\n",
    "pipe3 = Pipeline([('columntx', ColumnSelectTransformer(col_in)),\n",
    "                  ('dict_fix', DictAttEncoder()),\n",
    "                  ('dict_vec', DictVectorizer()),\n",
    "                 ('forest', RandomForestRegressor(n_jobs=-1))])\n",
    "\n",
    "kparams = { 'forest__n_estimators': [200, 300, 400],\n",
    "            'forest__max_depth': [10, 25, 40],\n",
    "            'forest__min_samples_split': [2, 10, 25, 50]}\n",
    "\n",
    "fn = GridSearchCV(pipe3, kparams, cv=5, scoring='neg_mean_squared_error')\n",
    "fn.fit(xtrain, ytrain)\n",
    "fn.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_in = ['attributes']\n",
    "pipe3 = Pipeline([('column tx', ColumnSelectTransformer(col_in)),\n",
    "                  ('dict fixer', DictAttEncoder()),\n",
    "                  ('dict vector', DictVectorizer()),\n",
    "                 ('forest model', RandomForestRegressor(n_jobs=-1, max_depth=40,\n",
    "                                                        n_estimators=300,\n",
    "                                                        min_samples_split=50))])\n",
    "\n",
    "pipe3.fit(xtrain, ytrain)\n",
    "\n",
    "print(pred_score(pipe3, xtest, ytest)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAndResidualRegressor(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.data = X\n",
    "        self.y_act = y\n",
    "\n",
    "        self.data_model1 = RandomForestRegressor(n_jobs=-1, max_depth=40,\n",
    "                                                        n_estimators=300,\n",
    "                                                        min_samples_split=50)\n",
    "        #self.data_model2 = Ridge(alpha=3.0)\n",
    "        self.data_model2 = RandomForestRegressor(n_jobs=-1, max_depth=40,\n",
    "                                                        n_estimators=300,\n",
    "                                                        min_samples_split=50)\n",
    "\n",
    "        self.data_model1.fit(self.data, self.y_act)\n",
    "        self.y_est = self.data_model1.predict(self.data)\n",
    "        self.y_res = self.y_act - self.y_est\n",
    "\n",
    "        self.data_model2.fit(self.data, self.y_res)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_predict = self.data_model1.predict(X) + self.data_model2.predict(X)\n",
    "\n",
    "        return y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_in = ['attributes']\n",
    "pipe4 = Pipeline([('column tx', ColumnSelectTransformer(col_in)),\n",
    "                  ('dict fixer', DictAttEncoder()),\n",
    "                  ('dict vector', DictVectorizer()),\n",
    "                  ('data res model', DataAndResidualRegressor())])\n",
    "\n",
    "pipe4.fit(xtrain, ytrain)\n",
    "print(pred_score(pipe4, xtest, ytest)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Estimator Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "        #return self\n",
    "\n",
    "    # What needs to be done here?\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.estimator.fit(X,y)\n",
    "        return self\n",
    "\n",
    "    # Fit the stored estimator.\n",
    "    # Question: what should be returned?\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.y_est = self.estimator.predict(X)\n",
    "        self.y_out = [[i] for i in self.y_est]\n",
    "\n",
    "        return self.y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use predict on the stored estimator as a \"transformation\".\n",
    "# Be sure to return a 2-D array.\n",
    "\n",
    "############################################################\n",
    "\n",
    "data = dill.load(open('data.pkd', 'rb'))\n",
    "star_ratings = [row['stars'] for row in data]\n",
    "\n",
    "city_est = CityEstimator()\n",
    "city_trans = EstimatorTransformer(city_est)\n",
    "\n",
    "city_trans.fit(data, star_ratings)\n",
    "assert ([r[0] for r in city_trans.transform(data[:5])]\n",
    "        == city_est.predict(data[:5]))\n",
    "\n",
    "\n",
    "\n",
    "union = FeatureUnion([('city est', city_trans),\n",
    "                      ('lat long', latlong_trans),\n",
    "                      ('cat mod', cat_trans),\n",
    "                      ('att mod', att_trans)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "city_trans = EstimatorTransformer(city_est)\n",
    "latlong_trans = EstimatorTransformer(pipe)\n",
    "cat_trans = EstimatorTransformer(pipe2)\n",
    "att_trans = EstimatorTransformer(pipe4)\n",
    "\n",
    "\n",
    "union = FeatureUnion([('city est', city_trans),\n",
    "                      ('lat long', latlong_trans),\n",
    "                      ('cat mod', cat_trans),\n",
    "                      ('att mod', att_trans)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "#lr_model = RandomForestRegressor(n_estimators=20)\n",
    "\n",
    "pipe5 = Pipeline([('columns all', union),\n",
    "                 ('lin model', lr_model)])\n",
    "\n",
    "pipe5.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5_y, p5_score = pred_score(pipe5, xtest, ytest)\n",
    "print(p5_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_venue = list(range(0,len(xtest)))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(city_venue[0:100], ytest[0:100], 'r.' ,label='Actual')\n",
    "plt.plot(city_venue[0:100], pipe5_y[0:100], 'bo' ,label='Pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_venue = list(range(0,len(xtest)))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(city_venue[0:100], ytest[0:100], 'r.' ,label='Actual')\n",
    "plt.plot(city_venue[0:100], city_test_pred[0:100], 'bo' ,label='Pred')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
